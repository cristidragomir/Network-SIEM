{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Generator, Optional\n",
    "from io import IOBase\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logger = logging.getLogger('SIEM')\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "load_dotenv()\n",
    "api_token = os.getenv('API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_follow(file: IOBase) -> Generator[str, None, None]:\n",
    "    file.seek(0, 2)\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if line:\n",
    "            yield line\n",
    "            continue\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def papertrail_tail(token: str) -> Generator[str, None, None]:\n",
    "    url = \"https://papertrailapp.com/api/v1/events/search.json\"\n",
    "    headers = {\"X-Papertrail-Token\": token}\n",
    "\n",
    "    tail = False\n",
    "    min_id = None\n",
    "    limit = 10000\n",
    "\n",
    "    while True:\n",
    "        params = {\"limit\": limit}\n",
    "        if tail and min_id:\n",
    "            params[\"min_id\"] = min_id\n",
    "        else:\n",
    "            params[\"min_time\"] = int(time.time()) - 10\n",
    "        \n",
    "        r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        tail = data.get(\"tail\", False)\n",
    "        min_id = data.get(\"max_id\", None)\n",
    "        yield from (e[\"message\"] for e in data[\"events\"])\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PacketInfo:\n",
    "    \"\"\" Information about a network packet\"\"\"\n",
    "    timestamp: str\n",
    "    protocol: str\n",
    "    src: str\n",
    "    dst: str\n",
    "    data: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCPDumpParser:\n",
    "    def __init__(self):\n",
    "        self.current_packet_content = \"\"\n",
    "        \n",
    "    def parse_tcpdump(self, log: str):\n",
    "        pattern = re.compile(r'(\\d+:\\d+:\\d+\\.\\d+) (\\w+) ([a-zA-Z0-9.]+) > ([a-zA-Z0-9.]+): (.+)$')\n",
    "        lines = log.split('\\n')\n",
    "        for line in lines:\n",
    "            match = pattern.match(line)\n",
    "            if match:\n",
    "                if self.current_packet_content:\n",
    "                    yield PacketInfo(*self.current_packet_content)\n",
    "                    \n",
    "                if match.group(2) == 'IP':\n",
    "                    self.current_packet_content = list(match.groups())\n",
    "                else:\n",
    "                    self.current_packet_content = \"\"\n",
    "                \n",
    "            else:\n",
    "                if not \"ARP\" in line and self.current_packet_content:\n",
    "                    self.current_packet_content[-1] += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = TCPDumpParser()\n",
    "for line in papertrail_tail(api_token):\n",
    "    # print(line)\n",
    "    for pkt in parser.parse_tcpdump(line):\n",
    "      print(pkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port scan detection\n",
    "packet_counts = {}\n",
    "\n",
    "time_window = timedelta(seconds=10)\n",
    "packet_threshold = 5\n",
    "\n",
    "start_time = None\n",
    "\n",
    "parser = TCPDumpParser()\n",
    "for line in papertrail_tail(api_token):\n",
    "    for pkt in parser.parse_tcpdump(line):\n",
    "        if not pkt:\n",
    "            logger.warning(f\"Packet format error: {line}\")\n",
    "        else:\n",
    "            logger.info(f\"Packet from {pkt.src} to {pkt.dst}: {pkt.data}\")\n",
    "\n",
    "            pkt_time = datetime.strptime(pkt.timestamp, \"%H:%M:%S.%f\")\n",
    "\n",
    "            if start_time is None or pkt_time - start_time > time_window:\n",
    "                packet_counts.clear()\n",
    "                start_time = pkt_time\n",
    "                \n",
    "            if pkt.dst not in packet_counts:\n",
    "                packet_counts[pkt.dst] = 0\n",
    "            else:\n",
    "                packet_counts[pkt.dst] += 1\n",
    "            \n",
    "            if packet_counts[pkt.dst] > packet_threshold:\n",
    "                logger.critical(f\"Port scan attack detected from: {pkt.src}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOS (SYN flood) detection\n",
    "syn_counts = {}\n",
    "\n",
    "time_window = timedelta(seconds=10)\n",
    "packet_threshold = 1000\n",
    "\n",
    "start_time = None\n",
    "\n",
    "parser = TCPDumpParser()\n",
    "for line in papertrail_tail(api_token):\n",
    "    for pkt in parser.parse_tcpdump(line):\n",
    "        if not pkt:\n",
    "            logger.warning(f\"Packet format error: {line}\")\n",
    "        else:\n",
    "            logger.info(f\"Packet from {pkt.src} to {pkt.dst}: {pkt.data}\")\n",
    "\n",
    "            pkt_time = datetime.strptime(pkt.timestamp, \"%H:%M:%S.%f\")\n",
    "\n",
    "            if start_time is None or pkt_time - start_time > time_window:\n",
    "                syn_counts.clear()\n",
    "                start_time = pkt_time\n",
    "\n",
    "            if pkt.protocol == \"TCP\" and \"S\" in pkt.data:\n",
    "                if pkt.dst not in syn_counts:\n",
    "                    syn_counts[pkt.dst] = 0\n",
    "                else:\n",
    "                    syn_counts[pkt.dst] += 1\n",
    "\n",
    "            if syn_counts[pkt.dst] > packet_threshold:\n",
    "                logger.critical(f\"DOS (SYN flood) attack from: {pkt.src}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arp_reply(line: str) -> Optional[PacketInfo]:\n",
    "    pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2}.\\d+) (\\w+), Reply (\\d+\\.\\d+\\.\\d+\\.\\d+) is-at ([0-9a-fA-F:]+), (.+)$')\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        return PacketInfo(*list(match.groups()))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARP Cache Poisoning detection\n",
    "arps = {}\n",
    "packet_window = 10\n",
    "\n",
    "for line in papertrail_tail(api_token):\n",
    "    pkt = parse_arp_reply(line)\n",
    "    if not pkt:\n",
    "        logger.warning(f\"Packet format error: {line}\")\n",
    "    else:\n",
    "        logger.info(f\"Packet from {pkt.src} to {pkt.dst}: {pkt.data}\")\n",
    "\n",
    "        if pkt.src not in arps:\n",
    "            arps[pkt.src] = [pkt.dst]\n",
    "        elif len(arps[pkt.src]) < packet_window:\n",
    "            arps[pkt.src].append(pkt.dst)\n",
    "        else:\n",
    "            arps[pkt.src] = arps[pkt.src][1:] + [pkt.dst]\n",
    "            if len(set(arps[pkt.src])) > 1:\n",
    "                logger.critical(f\"Possible ARP cache poisoning detected for IP {pkt.src}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force detection\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "packet_counts = {}\n",
    "\n",
    "time_window = timedelta(minutes=10)\n",
    "attempts_threshold = 2\n",
    "\n",
    "start_time = None\n",
    "failed_attempts = defaultdict(list)\n",
    "\n",
    "parser = TCPDumpParser()\n",
    "for line in papertrail_tail(api_token):\n",
    "    for pkt in parser.parse_tcpdump(line):\n",
    "        if not pkt:\n",
    "            logger.warning(f\"Packet format error: {line}\")\n",
    "        else:\n",
    "            logger.info(f\"Packet from {pkt.src} to {pkt.dst}: {pkt.data}\")\n",
    "            \n",
    "            pkt_time = datetime.strptime(pkt.timestamp, \"%H:%M:%S.%f\")\n",
    "\n",
    "            if start_time is None or pkt_time - start_time > time_window:\n",
    "                failed_attempts.clear()\n",
    "                start_time = pkt_time\n",
    "            \n",
    "            match = re.search(r'\\{.*\\}', pkt.data)\n",
    "            if match:\n",
    "                json_data = match.group(0)\n",
    "                j = json.loads(json_data)\n",
    "                if \"email\" in j:\n",
    "                    failed_attempts[j['email']].append(j)\n",
    "\n",
    "                    if len(failed_attempts[j['email']]) > attempts_threshold:\n",
    "                        print(f'Potential brute force attack detected on email address {j[\"email\"]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force detection\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "packet_counts = {}\n",
    "\n",
    "time_window = timedelta(minutes=10)\n",
    "attempts_threshold = 2\n",
    "\n",
    "start_time = None\n",
    "failed_attempts = defaultdict(list)\n",
    "\n",
    "def detect_sql_injection(input_string):\n",
    "    patterns = [\n",
    "        # SQL comment-style injections\n",
    "        r'(--\\s*\\d)',\n",
    "        r'(--\\s*[a-zA-z])',\n",
    "        r'(#\\s*\\d)',\n",
    "        r'(#\\s*[a-zA-z])',\n",
    "        # Stacked queries\n",
    "        r';',\n",
    "        # OR and UNION-based injections\n",
    "        r'(\\s+or\\s+)',\n",
    "        r'(\\s+union\\s+)',\n",
    "        # Basic SQL injections\n",
    "        r'(\\'\\s*=\\s*\\')',\n",
    "        r'(\\'\\s*or\\s*\\')',\n",
    "        # Time-delay injections\n",
    "        r'(waitfor\\s+delay)',\n",
    "        # Out-of-band injections\n",
    "        r'(;\\s*exec\\s+master..xp_cmdshell)',\n",
    "        # Other potentially harmful SQL keywords\n",
    "        r'(\\bdrop\\b)',\n",
    "        r'(\\bupdate\\b)',\n",
    "        r'(\\bdelete\\b)',\n",
    "        r'(\\binsert\\b)',\n",
    "        r'(\\bshutdown\\b)',\n",
    "        r'(\\bpowershell\\b)',\n",
    "        r'(\\bnet\\s+user\\b)',\n",
    "        r'(\\bexec\\b)',\n",
    "        r'(\\bdeclare\\b)',\n",
    "        r'(\\bcreate\\b)',\n",
    "        r'(\\balter\\b)',\n",
    "        r'(\\bdrop\\b)',\n",
    "        r'(\\btruncate\\b)',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, input_string, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "parser = TCPDumpParser()\n",
    "for line in papertrail_tail(api_token):\n",
    "    for pkt in parser.parse_tcpdump(line):\n",
    "        if not pkt:\n",
    "            logger.warning(f\"Packet format error: {line}\")\n",
    "        else:\n",
    "            logger.info(f\"Packet from {pkt.src} to {pkt.dst}: {pkt.data}\")\n",
    "            \n",
    "            pkt_time = datetime.strptime(pkt.timestamp, \"%H:%M:%S.%f\")\n",
    "\n",
    "            if start_time is None or pkt_time - start_time > time_window:\n",
    "                failed_attempts.clear()\n",
    "                start_time = pkt_time\n",
    "            \n",
    "            match = re.search(r'\\{.*\\}', pkt.data)\n",
    "            if match:\n",
    "                json_data = match.group(0)\n",
    "                print(json_data)\n",
    "                if detect_sql_injection(json_data):\n",
    "                    print(f'Potential SQL injection detected: {json_data}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
